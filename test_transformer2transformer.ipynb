{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 102 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score(precision=0.16888957961119538, recall=0.1740076658191007, fmeasure=0.1668065567031357)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import nlp\n",
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizer, EncoderDecoderModel\n",
    "tokenizer = BertTokenizer.from_pretrained(\"patrickvonplaten/bert2bert-cnn_dailymail-fp16\")\n",
    "model = EncoderDecoderModel.from_pretrained(\"patrickvonplaten/bert2bert-cnn_dailymail-fp16\")\n",
    "model.to(\"cuda\")\n",
    "test_dataset = nlp.load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"test\")\n",
    "# test_dataset = load_dataset('cnn_dailymail', \"3.0.0\", split='test', ignore_verifications=True)\n",
    "\n",
    "batch_size = 128\n",
    "# map data correctly\n",
    "def generate_summary(batch):\n",
    "    # Tokenizer will automatically set [BOS] <text> [EOS]\n",
    "    # cut off at BERT max length 512\n",
    "    inputs = tokenizer(batch[\"article\"], padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "    input_ids = inputs.input_ids.to(\"cuda\")\n",
    "    attention_mask = inputs.attention_mask.to(\"cuda\")\n",
    "    outputs = model.generate(input_ids, attention_mask=attention_mask)\n",
    "    # all special tokens including will be removed\n",
    "    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    batch[\"pred\"] = output_str\n",
    "    return batch\n",
    "results = test_dataset.map(generate_summary, batched=True, batch_size=batch_size, remove_columns=[\"article\"])\n",
    "# load rouge for validation\n",
    "rouge = nlp.load_metric(\"rouge\")\n",
    "pred_str = results[\"pred\"]\n",
    "label_str = results[\"highlights\"]\n",
    "rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"])[\"rouge2\"].mid\n",
    "print(rouge_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import EncoderDecoderConfig, EncoderDecoderModel, AutoTokenizer\n",
    "\n",
    "# encoder_decoder_config = EncoderDecoderConfig.from_pretrained('./models/bert2bert/2/checkpoint-4500')\n",
    "# bert2bert_model = EncoderDecoderModel.from_pretrained('./models/bert2bert/2/checkpoint-4500', config=encoder_decoder_config)\n",
    "# bert_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "\n",
    "encoder_decoder_config = EncoderDecoderConfig.from_pretrained('./models/bertweet2bertweet/2/checkpoint-3500')\n",
    "model = EncoderDecoderModel.from_pretrained('./models/bertweet2bertweet/2/checkpoint-3500', config=encoder_decoder_config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tweetNormalizer import normalizeTweet\n",
    "\n",
    "# load train and validation data\n",
    "train_dataset = pd.read_json(\"WNUT2015_dataset/train_data.json\", orient=\"records\")\n",
    "val_dataset = pd.read_json(\"WNUT2015_dataset/test_truth.json\", orient=\"records\")\n",
    "\n",
    "#make_sentence = lambda x : \" \".join(x)\n",
    "make_sentence = lambda x : normalizeTweet(\" \".join(x)).lower()\n",
    "\n",
    "train_dataset['input_sentence'] = train_dataset['input'].apply(make_sentence)\n",
    "train_dataset['output_sentence'] = train_dataset['output'].apply(make_sentence)\n",
    "val_dataset['input_sentence'] = val_dataset['input'].apply(make_sentence)\n",
    "val_dataset['output_sentence'] = val_dataset['output'].apply(make_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 2 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 2 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet:  @user yeh but still that's wild lol\n",
      "model:  @user yeah but still that's wild laughing out loud\n",
      "label:  @user yeah but still that's wild laughing out loud\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 2 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet:  dick in janice , im poppin xanax and speakin spanish .\n",
      "model:  dick in janice, i'm popping xanax and talking about miami.\n",
      "label:  dick in janice , i'm popping xanax and speaking spanish .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 2 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet:  ucsb i fear the next rampage will b cuz media told us everything #elliotrodger ever diid . to get ratings . #tcot #notonemore #knifesense\n",
      "model:  uci believe i swear the ultimate will be home because everyone told us #lierot ever died to get diors. #nototheshire #no#mekenekenekkenene\n",
      "label:  ucsb i fear the next rampage will because media told us everything #elliotrodger ever did . to get ratings . #tcot #notonemore #knifesense\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 2 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet:  rt @user : @user @user @user not even gays are gonna look to u lmao\n",
      "model:  rt @user : @user @user not even gay gay are gonna look to you laughing my ass off\n",
      "label:  rt @user : @user @user @user not even gays are gonna look to you laughing my ass off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 2 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet:  @user @user @user card in 5 mins is with wh but this was the game so far bk lol but how to find who the ref is\n",
      "model:  @user @user laughing out loud card in 5 is with what is this but this was so big back to front but how to find how find the person is\n",
      "label:  @user @user @user card in 5 minutes is with wh but this was the game so far bk laughing out loud but how to find who the ref is\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 2 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet:  @user haha oh okk ! yeaah , they've been dating for a while now ! ! they seem crazy cute ! ! !\n",
      "model:  @user haha oh okay! yeah they's definitely had a million while for a lot now! they really cute!!\n",
      "label:  @user haha oh okay ! yeah , they've been dating for a while now ! ! they seem crazy cute ! ! !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 2 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet:  samsung working on oculus rift-like vr headsets for galaxy devices : report - firstpost httpurl\n",
      "model:  samsung working on ococro like t-ved headtions for galaxy comments : first - httpurl\n",
      "label:  samsung working on oculus rift-like vr headsets for galaxy devices : report - firstpost httpurl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 2 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet:  rt @user : best snapchat i've seen all day lmfao httpurl\n",
      "model:  rt @user : best snapchat i've seen all day laughing my ass off httpurl\n",
      "label:  rt @user : best snapchat i've seen all day laughing my fucking ass off httpurl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 2 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet:  legends indeed rt @user : feela sistah spoken word collective ... #legendsofsapoetry httpurl\n",
      "model:  legendary indeed rt @user : favaa a sekword word... #bringealafoodsa httpurl\n",
      "label:  legends indeed rt @user : feels sistah spoken word collective ... #legendsofsapoetry httpurl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 2 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet:  thisnewssoccer : adam lallana pilih tottenham hotspur ketimbang liverpool httpurl #thisisfootball_id\n",
      "model:  this ssssecarro : adam llihaal to hihtottenham #nobangbangparis httpurl #artist@@\n",
      "label:  this news soccer : adam lallana pilih tottenham hotspur ketimbang liverpool httpurl #thisisfootball_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 2 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet:  enter to #win a prize pack of lindor truffles and lindor sticks ( arcv $ 52 ) from lindt & @user ! #giveaway httpurl\n",
      "model:  invite to win a prize of cup or ffle and lindffle or sticks ( 15 ) $ 15 from codet & @user giveaway! httpurl\n",
      "label:  enter to #win a prize pack of lindor truffles and lindor sticks ( arcv $ 52 ) from lindt & @user ! #giveaway httpurl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 2 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet:  httpurl #joy \" ... #suffering is the result of an aggressive mind . \" . pema chodron\n",
      "model:  httpurl #lovely... \" #sadness is the results of an attack. \". #pms\n",
      "label:  httpurl #joy \" ... #suffering is the result of an aggressive mind . \" . pema chodron\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 2 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet:  rt @user : we r doin a fucken movie with lionsgate how did we even get here from barking on a train bahahahaha\n",
      "model:  rt @user : we are doing a fucking movie with lioguards what we even got here from bouncing on a bikini hahahaha\n",
      "label:  rt @user : we are doing a fucking movie with lionsgate how did we even get here from barking on a train bahahahaha\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 2 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet:  lol . don't act cute here pls\n",
      "model:  laughing out loud. don't act cute here please\n",
      "label:  laughing out loud . don't act cute here please\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 2 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet:  rt @user : idek why i bother ... smh\n",
      "model:  rt @user : i don't know why i worry... shaking my head\n",
      "label:  rt @user : i don't even know why i bother ... shaking my head\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 2 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet:  rt @user : [ hq ] 140526 xiumin , luhan @user mbc idol futsal championship ( cr . shade of the bloom ) httpurl\n",
      "model:  rt @user : [ hq ] 140526 xiumin, luhan @user mbc idol futsal championship ( cr : the lovely ) httpurl\n",
      "label:  rt @user : [ hq ] 140526 xiumin , luhan @user mbc idol futsal championship ( cr . shade of the bloom ) httpurl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 2 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet:  @user ayy skiperooo wassup cuz what u mean by marlton ?\n",
      "model:  @user alright scooperoo what's what because you mean marlton?\n",
      "label:  @user ayy skiperooo what's up because what you mean by marlton ?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 2 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet:  rt @user : sean , darragh and i , in croke park ! unbelievable weekend ! httpurl\n",
      "model:  rt @user : sean, darragh and i, in croke park! unbelievable weekend! httpurl\n",
      "label:  rt @user : sean , darragh and i , in croke park ! unbelievable weekend ! httpurl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 2 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet:  @user umm i thought that convo was pretty funny soooooo\n",
      "model:  @user umm i thought that conversation was pretty funny so\n",
      "label:  @user umm i thought that conversation was pretty funny so\n",
      "tweet:  stop be so fucken gay you three aint nobody got time for that @user @user @user\n",
      "model:  stop be so fucking gay you three ain't got nobody got time for that @user @user\n",
      "label:  stop be so fucking gay you three ain't nobody got time for that @user @user @user\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 20):\n",
    "#     print(\"example\"+str(i))\n",
    "    tweet_text = val_dataset.iloc[i]['input_sentence']\n",
    "    normal_english = val_dataset.iloc[i]['output_sentence']\n",
    "\n",
    "    input_ids = tokenizer(tweet_text, return_tensors=\"pt\").input_ids\n",
    "    output_ids = model.generate(input_ids)\n",
    "\n",
    "    print(\"tweet: \", tweet_text)\n",
    "    print(\"model: \", tokenizer.decode(output_ids[0], skip_special_tokens=True))\n",
    "    print(\"label: \", normal_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 2 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet:  WE R DOIN A FUCKEN movie, it's so bad. lol.\n",
      "model:  we are doing a fucking movie e's, it's so bad. laughing out loud\n"
     ]
    }
   ],
   "source": [
    "tweet_text = \"WE R DOIN A FUCKEN MOVIE, it's so bad. lol.\"\n",
    "\n",
    "input_ids = tokenizer(tweet_text, return_tensors=\"pt\").input_ids\n",
    "output_ids = model.generate(input_ids)\n",
    "\n",
    "print(\"tweet: \", tweet_text)\n",
    "print(\"model: \", tokenizer.decode(output_ids[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pre-pocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tweetNormalizer import normalizeTweet\n",
    "import re\n",
    "\n",
    "# load train and validation data\n",
    "train_dataset = pd.read_json(\"WNUT2015_dataset/train_data.json\", orient=\"records\")\n",
    "val_dataset = pd.read_json(\"WNUT2015_dataset/test_truth.json\", orient=\"records\")\n",
    "\n",
    "train_dataset = train_dataset[:100]\n",
    "val_dataset = val_dataset[:5]\n",
    "\n",
    "\n",
    "make_sentence = lambda x : normalizeTweet(\" \".join(x))\n",
    "\n",
    "train_dataset['input_sentence'] = train_dataset['input'].apply(make_sentence)\n",
    "train_dataset['output_sentence'] = train_dataset['output'].apply(make_sentence)\n",
    "val_dataset['input_sentence'] = val_dataset['input'].apply(make_sentence)\n",
    "val_dataset['output_sentence'] = val_dataset['output'].apply(make_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> RT @USER : [ HQ ] 14@@ 05@@ 26 Xi@@ umin , Luhan @USER MBC Idol Fut@@ sal Championship ( cr . shade of the bloom ) HTTPURL </s>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertweetTokenizer, AutoTokenizer\n",
    "from tweetNormalizer import normalizeTweet\n",
    "\n",
    "#line = \"SC has first two presumptive cases of coronavirus, DHEC confirms https://postandcourier.com/health/covid19/sc-has-first-two-presumptive-cases-of-coronavirus-dhec-confirms/article_bddfe4ae-5fd3-11ea-9ce4-5f495366cee6.html?utm_medium=social&utm_source=twitter&utm_campaign=user-share… via @postandcourier\"\n",
    "line = \"RT @EXOffical : [ HQ ] 140526 Xiumin , Luhan @ MBC Idol Futsal Championship ( cr . shade of the bloom ) http://t.co/ToBKl76SzP\"\n",
    "\n",
    "\n",
    "tokenizer = BertweetTokenizer.from_pretrained(\"vinai/bertweet-base\")\n",
    "input_ids = torch.tensor([tokenizer.encode(normalizeTweet(line))])\n",
    "print(' '.join(tokenizer.convert_ids_to_tokens(input_ids[0], skip_special_tokens=False)))\n",
    "\n",
    "# tokenizer = BertweetTokenizer.from_pretrained(\"vinai/bertweet-base\", normalization=True)\n",
    "# input_ids = torch.tensor([tokenizer.encode(line)])\n",
    "# print(' '.join(tokenizer.convert_ids_to_tokens(input_ids[0], skip_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64000\n",
      "0 64000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<s>',\n",
       " 'eos_token': '</s>',\n",
       " 'unk_token': '<unk>',\n",
       " 'sep_token': '</s>',\n",
       " 'pad_token': '<pad>',\n",
       " 'cls_token': '<s>',\n",
       " 'mask_token': '<mask>',\n",
       " 'additional_special_tokens': \"['@USER', 'HTTPURL']\"}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", normalization=True)\n",
    "special_tokens_dict = {'additional_special_tokens': ['@USER','HTTPURL']}\n",
    "print(tokenizer.vocab_size)\n",
    "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "print(num_added_toks, tokenizer.vocab_size)\n",
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30522\n",
      "2 30522\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'unk_token': '[UNK]',\n",
       " 'sep_token': '[SEP]',\n",
       " 'pad_token': '[PAD]',\n",
       " 'cls_token': '[CLS]',\n",
       " 'mask_token': '[MASK]',\n",
       " 'additional_special_tokens': \"['@USER', 'HTTPURL']\"}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "special_tokens_dict = {'additional_special_tokens': ['@USER','HTTPURL']}\n",
    "print(tokenizer.vocab_size)\n",
    "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "print(num_added_toks, tokenizer.vocab_size)\n",
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@USER', 'HTTPURL']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.additional_special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<|endoftext|>',\n",
       " 'eos_token': '<|endoftext|>',\n",
       " 'unk_token': '<|endoftext|>',\n",
       " 'additional_special_tokens': \"['@USER', 'HTTPURL']\"}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "special_tokens_dict = {'additional_special_tokens': ['@USER','HTTPURL']}\n",
    "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "print(tokenizer.vocab_size)\n",
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50265\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<s>',\n",
       " 'eos_token': '</s>',\n",
       " 'unk_token': '<unk>',\n",
       " 'sep_token': '</s>',\n",
       " 'pad_token': '<pad>',\n",
       " 'cls_token': '<s>',\n",
       " 'mask_token': '<mask>',\n",
       " 'additional_special_tokens': \"['@USER', 'HTTPURL']\"}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "special_tokens_dict = {'additional_special_tokens': ['@USER','HTTPURL']}\n",
    "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "print(tokenizer.vocab_size)\n",
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sc has first two presumptive cases of coronavirus, dhec confirms HTTPURL... via @USER'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = \"SC has first two presumptive cases of coronavirus, DHEC confirms https://postandcourier.com/health/covid19/sc-has-first-two-presumptive-cases-of-coronavirus-dhec-confirms/article_bddfe4ae-5fd3-11ea-9ce4-5f495366cee6.html?utm_medium=social&utm_source=twitter&utm_campaign=user-share… via @postandcourier\"\n",
    "\n",
    "ENCODER = \"bert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(ENCODER)\n",
    "\n",
    "if ENCODER==\"bert-base-uncased\":\n",
    "    # CLS token will work as BOS token, SEP token will work as EOS token\n",
    "    tokenizer.bos_token = tokenizer.cls_token\n",
    "    tokenizer.eos_token = tokenizer.sep_token\n",
    "\n",
    "special_tokens_dict = {'additional_special_tokens': ['@USER','HTTPURL']}\n",
    "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "input_ids = tokenizer.encode(normalizeTweet(line))\n",
    "\n",
    "for rm_id in [tokenizer.bos_token_id, tokenizer.eos_token_id, tokenizer.pad_token_id]:\n",
    "    if rm_id in input_ids:\n",
    "        input_ids.remove(rm_id)\n",
    "\n",
    "input_ids = torch.tensor([input_ids])\n",
    "\n",
    "input_sent = tokenizer.decode(input_ids[0], skip_special_tokens=False)\n",
    "input_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertLMHeadModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertLMHeadModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.value.weight', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'cls.predictions.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# set EncoderDecoderModel\n",
    "model = EncoderDecoderModel.from_encoder_decoder_pretrained(\"bert-base-uncased\", \"bert-base-uncased\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 46916674058320 acquired on /home/zonghaiyao/.cache/huggingface/datasets/dcd4134ec0ad23f318793c6f8b77745d97efebf4b194bcb3c1ce90f867bec0cc.07d7a1ea4a0063d16947f4a5b5a7ad98ca747e989e62fd0b2c5aa4b606f70aca.py.lock\n",
      "INFO:filelock:Lock 46916674058320 released on /home/zonghaiyao/.cache/huggingface/datasets/dcd4134ec0ad23f318793c6f8b77745d97efebf4b194bcb3c1ce90f867bec0cc.07d7a1ea4a0063d16947f4a5b5a7ad98ca747e989e62fd0b2c5aa4b606f70aca.py.lock\n",
      "INFO:filelock:Lock 46916461548048 acquired on /home/zonghaiyao/.cache/huggingface/datasets/c7db30bf448719bd2c2ee7c233832963ab2e0b85e984dda4f577016390fa0e85.7927df63b30f94ac549ad2d2e3c61c5089402aacb0ab0478007e0abfe3431378.py.lock\n",
      "INFO:filelock:Lock 46916461548048 released on /home/zonghaiyao/.cache/huggingface/datasets/c7db30bf448719bd2c2ee7c233832963ab2e0b85e984dda4f577016390fa0e85.7927df63b30f94ac549ad2d2e3c61c5089402aacb0ab0478007e0abfe3431378.py.lock\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.crossattention.bias', 'h.0.crossattention.masked_bias', 'h.0.crossattention.c_attn.weight', 'h.0.crossattention.c_attn.bias', 'h.0.crossattention.q_attn.weight', 'h.0.crossattention.q_attn.bias', 'h.0.crossattention.c_proj.weight', 'h.0.crossattention.c_proj.bias', 'h.0.ln_cross_attn.weight', 'h.0.ln_cross_attn.bias', 'h.1.crossattention.bias', 'h.1.crossattention.masked_bias', 'h.1.crossattention.c_attn.weight', 'h.1.crossattention.c_attn.bias', 'h.1.crossattention.q_attn.weight', 'h.1.crossattention.q_attn.bias', 'h.1.crossattention.c_proj.weight', 'h.1.crossattention.c_proj.bias', 'h.1.ln_cross_attn.weight', 'h.1.ln_cross_attn.bias', 'h.2.crossattention.bias', 'h.2.crossattention.masked_bias', 'h.2.crossattention.c_attn.weight', 'h.2.crossattention.c_attn.bias', 'h.2.crossattention.q_attn.weight', 'h.2.crossattention.q_attn.bias', 'h.2.crossattention.c_proj.weight', 'h.2.crossattention.c_proj.bias', 'h.2.ln_cross_attn.weight', 'h.2.ln_cross_attn.bias', 'h.3.crossattention.bias', 'h.3.crossattention.masked_bias', 'h.3.crossattention.c_attn.weight', 'h.3.crossattention.c_attn.bias', 'h.3.crossattention.q_attn.weight', 'h.3.crossattention.q_attn.bias', 'h.3.crossattention.c_proj.weight', 'h.3.crossattention.c_proj.bias', 'h.3.ln_cross_attn.weight', 'h.3.ln_cross_attn.bias', 'h.4.crossattention.bias', 'h.4.crossattention.masked_bias', 'h.4.crossattention.c_attn.weight', 'h.4.crossattention.c_attn.bias', 'h.4.crossattention.q_attn.weight', 'h.4.crossattention.q_attn.bias', 'h.4.crossattention.c_proj.weight', 'h.4.crossattention.c_proj.bias', 'h.4.ln_cross_attn.weight', 'h.4.ln_cross_attn.bias', 'h.5.crossattention.bias', 'h.5.crossattention.masked_bias', 'h.5.crossattention.c_attn.weight', 'h.5.crossattention.c_attn.bias', 'h.5.crossattention.q_attn.weight', 'h.5.crossattention.q_attn.bias', 'h.5.crossattention.c_proj.weight', 'h.5.crossattention.c_proj.bias', 'h.5.ln_cross_attn.weight', 'h.5.ln_cross_attn.bias', 'h.6.crossattention.bias', 'h.6.crossattention.masked_bias', 'h.6.crossattention.c_attn.weight', 'h.6.crossattention.c_attn.bias', 'h.6.crossattention.q_attn.weight', 'h.6.crossattention.q_attn.bias', 'h.6.crossattention.c_proj.weight', 'h.6.crossattention.c_proj.bias', 'h.6.ln_cross_attn.weight', 'h.6.ln_cross_attn.bias', 'h.7.crossattention.bias', 'h.7.crossattention.masked_bias', 'h.7.crossattention.c_attn.weight', 'h.7.crossattention.c_attn.bias', 'h.7.crossattention.q_attn.weight', 'h.7.crossattention.q_attn.bias', 'h.7.crossattention.c_proj.weight', 'h.7.crossattention.c_proj.bias', 'h.7.ln_cross_attn.weight', 'h.7.ln_cross_attn.bias', 'h.8.crossattention.bias', 'h.8.crossattention.masked_bias', 'h.8.crossattention.c_attn.weight', 'h.8.crossattention.c_attn.bias', 'h.8.crossattention.q_attn.weight', 'h.8.crossattention.q_attn.bias', 'h.8.crossattention.c_proj.weight', 'h.8.crossattention.c_proj.bias', 'h.8.ln_cross_attn.weight', 'h.8.ln_cross_attn.bias', 'h.9.crossattention.bias', 'h.9.crossattention.masked_bias', 'h.9.crossattention.c_attn.weight', 'h.9.crossattention.c_attn.bias', 'h.9.crossattention.q_attn.weight', 'h.9.crossattention.q_attn.bias', 'h.9.crossattention.c_proj.weight', 'h.9.crossattention.c_proj.bias', 'h.9.ln_cross_attn.weight', 'h.9.ln_cross_attn.bias', 'h.10.crossattention.bias', 'h.10.crossattention.masked_bias', 'h.10.crossattention.c_attn.weight', 'h.10.crossattention.c_attn.bias', 'h.10.crossattention.q_attn.weight', 'h.10.crossattention.q_attn.bias', 'h.10.crossattention.c_proj.weight', 'h.10.crossattention.c_proj.bias', 'h.10.ln_cross_attn.weight', 'h.10.ln_cross_attn.bias', 'h.11.crossattention.bias', 'h.11.crossattention.masked_bias', 'h.11.crossattention.c_attn.weight', 'h.11.crossattention.c_attn.bias', 'h.11.crossattention.q_attn.weight', 'h.11.crossattention.q_attn.bias', 'h.11.crossattention.c_proj.weight', 'h.11.crossattention.c_proj.bias', 'h.11.ln_cross_attn.weight', 'h.11.ln_cross_attn.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import nlp\n",
    "import logging\n",
    "from datasets import load_metric\n",
    "from transformers import EncoderDecoderModel, Trainer, TrainingArguments, AutoTokenizer\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from tweetNormalizer import normalizeTweet\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "#change 6 places\n",
    "\n",
    "#bert-base-uncased, gpt2, roberta-base, vinai/bertweet-base\n",
    "RUN_NAME=\"bertweet2bertweet_share\"\n",
    "ENCODER = \"vinai/bertweet-base\"\n",
    "DECODER = \"gpt2\"\n",
    "tie_ENCODER_DECODER=False\n",
    "OUTPUT_DIR=\"./models/\"+RUN_NAME+\"/2/\"\n",
    "\n",
    "batch_size = 16   # set batch size here\n",
    "encoder_length = 128\n",
    "decoder_length = 128\n",
    "\n",
    "PATH_TO_TRAIN_DATA = \"WNUT2015_dataset/train_data.json\"\n",
    "PATH_TO_VAL_DATA = \"WNUT2015_dataset/test_truth.json\"\n",
    "is_normalizeTweet = True\n",
    "\n",
    "rouge = load_metric('rouge', experiment_id=7)\n",
    "bleu = load_metric('bleu', experiment_id=7)\n",
    "\n",
    "#---------------------------------------------------------------------------------------------\n",
    "# encoder tokenizer\n",
    "encoder_tokenizer = AutoTokenizer.from_pretrained(ENCODER)\n",
    "\n",
    "if ENCODER==\"bert-base-uncased\":\n",
    "    # CLS token will work as BOS token, SEP token will work as EOS token\n",
    "    encoder_tokenizer.bos_token = encoder_tokenizer.cls_token\n",
    "    encoder_tokenizer.eos_token = encoder_tokenizer.sep_token\n",
    "    \n",
    "# decoder tokenizer\n",
    "if DECODER==\"gpt2\":\n",
    "    # make sure GPT2 appends EOS in begin and end\n",
    "    def build_inputs_with_special_tokens(self, token_ids_0, token_ids_1=None):\n",
    "        outputs = [self.bos_token_id] + token_ids_0 + [self.eos_token_id]\n",
    "        return outputs\n",
    "    \n",
    "    AutoTokenizer.build_inputs_with_special_tokens = build_inputs_with_special_tokens\n",
    "    decoder_tokenizer = AutoTokenizer.from_pretrained(DECODER)\n",
    "    # set pad_token_id to unk_token_id -> be careful here as unk_token_id == eos_token_id == bos_token_id\n",
    "    decoder_tokenizer.pad_token = decoder_tokenizer.unk_token\n",
    "else:   \n",
    "    decoder_tokenizer = AutoTokenizer.from_pretrained(DECODER)\n",
    "\n",
    "if DECODER==\"bert-base-uncased\":\n",
    "    # CLS token will work as BOS token, SEP token will work as EOS token\n",
    "    decoder_tokenizer.bos_token = decoder_tokenizer.cls_token\n",
    "    decoder_tokenizer.eos_token = decoder_tokenizer.sep_token\n",
    "\n",
    "if is_normalizeTweet:\n",
    "    special_tokens_dict = {'additional_special_tokens': ['@USER','HTTPURL']}\n",
    "    num_added_toks_encoder = encoder_tokenizer.add_special_tokens(special_tokens_dict)\n",
    "    num_added_toks_decoder = decoder_tokenizer.add_special_tokens(special_tokens_dict)\n",
    "    print(num_added_toks_encoder, num_added_toks_decoder)\n",
    "    \n",
    "# set EncoderDecoderModel\n",
    "model = EncoderDecoderModel.from_encoder_decoder_pretrained(ENCODER, DECODER, tie_encoder_decoder = tie_ENCODER_DECODER)\n",
    "\n",
    "if is_normalizeTweet:\n",
    "    model.encoder.resize_token_embeddings(len(encoder_tokenizer))\n",
    "    model.encoder.resize_token_embeddings(len(decoder_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50256"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_tokenizer.convert_tokens_to_ids(\"@USER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaConfig {\n",
       "  \"architectures\": [\n",
       "    \"RobertaForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"max_position_embeddings\": 130,\n",
       "  \"model_type\": \"roberta\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"tokenizer_class\": \"BertweetTokenizer\",\n",
       "  \"type_vocab_size\": 1,\n",
       "  \"vocab_size\": 64001\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Config {\n",
       "  \"activation_function\": \"gelu_new\",\n",
       "  \"add_cross_attention\": true,\n",
       "  \"architectures\": [\n",
       "    \"GPT2LMHeadModel\"\n",
       "  ],\n",
       "  \"attn_pdrop\": 0.1,\n",
       "  \"bos_token_id\": 50256,\n",
       "  \"embd_pdrop\": 0.1,\n",
       "  \"eos_token_id\": 50256,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"is_decoder\": true,\n",
       "  \"layer_norm_epsilon\": 1e-05,\n",
       "  \"model_type\": \"gpt2\",\n",
       "  \"n_ctx\": 1024,\n",
       "  \"n_embd\": 768,\n",
       "  \"n_head\": 12,\n",
       "  \"n_inner\": null,\n",
       "  \"n_layer\": 12,\n",
       "  \"n_positions\": 1024,\n",
       "  \"resid_pdrop\": 0.1,\n",
       "  \"summary_activation\": null,\n",
       "  \"summary_first_dropout\": 0.1,\n",
       "  \"summary_proj_to_labels\": true,\n",
       "  \"summary_type\": \"cls_index\",\n",
       "  \"summary_use_proj\": true,\n",
       "  \"task_specific_params\": {\n",
       "    \"text-generation\": {\n",
       "      \"do_sample\": true,\n",
       "      \"max_length\": 50\n",
       "    }\n",
       "  },\n",
       "  \"vocab_size\": 50257\n",
       "}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method PreTrainedModel.resize_token_embeddings of EncoderDecoderModel(\n",
       "  (encoder): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50257, 768)\n",
       "      (position_embeddings): Embedding(130, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (decoder): GPT2LMHeadModel(\n",
       "    (transformer): GPT2Model(\n",
       "      (wte): Embedding(50257, 768)\n",
       "      (wpe): Embedding(1024, 768)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (h): ModuleList(\n",
       "        (0): Block(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (crossattention): Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (q_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_cross_attn): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (c_fc): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Block(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (crossattention): Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (q_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_cross_attn): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (c_fc): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): Block(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (crossattention): Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (q_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_cross_attn): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (c_fc): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): Block(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (crossattention): Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (q_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_cross_attn): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (c_fc): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): Block(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (crossattention): Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (q_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_cross_attn): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (c_fc): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): Block(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (crossattention): Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (q_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_cross_attn): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (c_fc): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): Block(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (crossattention): Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (q_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_cross_attn): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (c_fc): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): Block(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (crossattention): Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (q_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_cross_attn): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (c_fc): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): Block(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (crossattention): Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (q_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_cross_attn): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (c_fc): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): Block(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (crossattention): Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (q_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_cross_attn): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (c_fc): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): Block(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (crossattention): Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (q_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_cross_attn): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (c_fc): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): Block(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (crossattention): Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (q_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_cross_attn): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (c_fc): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set decoding params\n",
    "model.config.decoder_start_token_id = decoder_tokenizer.bos_token_id\n",
    "model.config.eos_token_id = decoder_tokenizer.eos_token_id\n",
    "model.config.max_length = decoder_length\n",
    "model.config.min_length = 0\n",
    "model.config.no_repeat_ngram_size = 3\n",
    "model.early_stopping = True\n",
    "model.length_penalty = 2.0\n",
    "model.num_beams = 4\n",
    "\n",
    "#-------------------------------------------------------------------------------------------\n",
    "# load train and validation data\n",
    "train_dataset = pd.read_json(PATH_TO_TRAIN_DATA, orient=\"records\")\n",
    "val_dataset = pd.read_json(PATH_TO_VAL_DATA, orient=\"records\")\n",
    "\n",
    "if is_normalizeTweet:\n",
    "    make_sentence = lambda x : normalizeTweet(\" \".join(x)).lower()\n",
    "else:\n",
    "    make_sentence = lambda x : \" \".join(x).lower()\n",
    "\n",
    "train_dataset['input_sentence'] = train_dataset['input'].apply(make_sentence)\n",
    "train_dataset['output_sentence'] = train_dataset['output'].apply(make_sentence)\n",
    "val_dataset['input_sentence'] = val_dataset['input'].apply(make_sentence)\n",
    "val_dataset['output_sentence'] = val_dataset['output'].apply(make_sentence)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_dataset)\n",
    "val_dataset = Dataset.from_pandas(val_dataset)\n",
    "\n",
    "# map data correctly\n",
    "def map_to_encoder_decoder_inputs(batch):\n",
    "    # Tokenizer will automatically set [BOS] <text> [EOS]\n",
    "    inputs = encoder_tokenizer(batch[\"input_sentence\"], padding=\"max_length\", truncation=True, max_length=encoder_length)\n",
    "    outputs = decoder_tokenizer(batch[\"output_sentence\"], padding=\"max_length\", truncation=True, max_length=decoder_length)\n",
    "\n",
    "    batch[\"input_ids\"] = inputs.input_ids\n",
    "    batch[\"attention_mask\"] = inputs.attention_mask\n",
    "\n",
    "    batch[\"decoder_input_ids\"] = outputs.input_ids\n",
    "    batch[\"labels\"] = outputs.input_ids.copy()\n",
    "    batch[\"decoder_attention_mask\"] = outputs.attention_mask\n",
    "    \n",
    "    if DECODER==\"gpt2\":\n",
    "        # complicated list comprehension here because pad_token_id alone is not good enough to know whether label should be excluded or not\n",
    "        batch[\"labels\"] = [\n",
    "            [-100 if mask == 0 else token for mask, token in mask_and_tokens] for mask_and_tokens in [zip(masks, labels) for masks, labels in zip(batch[\"decoder_attention_mask\"], batch[\"labels\"])]\n",
    "        ]\n",
    "    else:\n",
    "        # mask loss for padding\n",
    "        batch[\"labels\"] = [\n",
    "            [-100 if token == decoder_tokenizer.pad_token_id else token for token in labels] for labels in batch[\"labels\"]\n",
    "        ]\n",
    "    \n",
    "\n",
    "    assert all([len(x) == encoder_length for x in inputs.input_ids])\n",
    "    assert all([len(x) == decoder_length for x in outputs.input_ids])\n",
    "    \n",
    "    return batch\n",
    "\n",
    "# make train dataset ready\n",
    "train_dataset = train_dataset.map(\n",
    "    map_to_encoder_decoder_inputs, batched=True, batch_size=batch_size, remove_columns=[\"input_sentence\", \"output_sentence\"],\n",
    ")\n",
    "train_dataset.set_format(\n",
    "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",
    ")\n",
    "\n",
    "# same for validation dataset\n",
    "val_dataset = val_dataset.map(\n",
    "    map_to_encoder_decoder_inputs, batched=True, batch_size=batch_size, remove_columns=[\"input_sentence\", \"output_sentence\"],\n",
    ")\n",
    "val_dataset.set_format(\n",
    "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",
    ")\n",
    "        \n",
    "#-----------------------------------------------------------------------------------\n",
    "# load metrics for validation\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    # all unnecessary tokens are removed\n",
    "    pred_str = decoder_tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    labels_ids[labels_ids == -100] = decoder_tokenizer.eos_token_id\n",
    "    label_str = decoder_tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "    \n",
    "    metrics_rouge = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge1\", \"rouge2\", \"rouge3\", \"rouge4\", \"rougeL\", \"rougeLsum\"])\n",
    "\n",
    "    def batch_convert_ids_to_tokens(sequences, **kwargs):\n",
    "        return [decoder_tokenizer.convert_ids_to_tokens(seq, **kwargs) for seq in sequences]\n",
    "    \n",
    "    pred_tokens = batch_convert_ids_to_tokens(pred_ids, skip_special_tokens=True)\n",
    "    \n",
    "    def batch_convert_ids_to_tokens(sequences, **kwargs):\n",
    "        return [[decoder_tokenizer.convert_ids_to_tokens(seq, **kwargs)] for seq in sequences]\n",
    "    \n",
    "    label_tokens = batch_convert_ids_to_tokens(labels_ids, skip_special_tokens=True)\n",
    "    \n",
    "    metrics_bleu = bleu.compute(predictions=pred_tokens, references=label_tokens)\n",
    "    \n",
    "    return {\n",
    "        \"rouge1_precision\": round(metrics_rouge['rouge1'].mid.precision, 4),\n",
    "        \"rouge1_recall\": round(metrics_rouge['rouge1'].mid.recall, 4),\n",
    "        \"rouge1_fmeasure\": round(metrics_rouge['rouge1'].mid.fmeasure, 4),\n",
    "        \"rouge2_precision\": round(metrics_rouge['rouge2'].mid.precision, 4),\n",
    "        \"rouge2_recall\": round(metrics_rouge['rouge2'].mid.recall, 4),\n",
    "        \"rouge2_fmeasure\": round(metrics_rouge['rouge2'].mid.fmeasure, 4),\n",
    "        \"rouge3_precision\": round(metrics_rouge['rouge3'].mid.precision, 4),\n",
    "        \"rouge3_recall\": round(metrics_rouge['rouge3'].mid.recall, 4),\n",
    "        \"rouge3_fmeasure\": round(metrics_rouge['rouge3'].mid.fmeasure, 4),\n",
    "        \"rouge4_precision\": round(metrics_rouge['rouge4'].mid.precision, 4),\n",
    "        \"rouge4_recall\": round(metrics_rouge['rouge4'].mid.recall, 4),\n",
    "        \"rouge4_fmeasure\": round(metrics_rouge['rouge4'].mid.fmeasure, 4),\n",
    "        \"rougeL_precision\": round(metrics_rouge['rougeL'].mid.precision, 4),\n",
    "        \"rougeL_recall\": round(metrics_rouge['rougeL'].mid.recall, 4),\n",
    "        \"rougeL_fmeasure\": round(metrics_rouge['rougeL'].mid.fmeasure, 4),\n",
    "        \"rougeLsum_precision\": round(metrics_rouge['rougeLsum'].mid.precision, 4),\n",
    "        \"rougeLsum_recall\": round(metrics_rouge['rougeLsum'].mid.recall, 4),\n",
    "        \"rougeLsum_fmeasure\": round(metrics_rouge['rougeLsum'].mid.fmeasure, 4),\n",
    "        \"bleu\": round(metrics_bleu['bleu'], 4),\n",
    "    }\n",
    "        \n",
    "#----------------------------------------------------------------------------------------\n",
    "# begin train\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    predict_from_generate=True,\n",
    "    evaluate_during_training=True,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    logging_steps=20,\n",
    "    save_steps=500,\n",
    "    eval_steps=300,\n",
    "    overwrite_output_dir=True,\n",
    "    warmup_steps=50,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=30,\n",
    "    fp16=True,\n",
    "    run_name=RUN_NAME,\n",
    ")\n",
    "\n",
    "\n",
    "# instantiate trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")\n",
    "\n",
    "\n",
    "# start training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load train and validation data\n",
    "# train_df = pd.read_json(\"WNUT2015_dataset/train_data.json\", orient=\"records\")\n",
    "# val_df = pd.read_json(\"WNUT2015_dataset/test_truth.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 41 41 41\n",
      "4 4 4 4\n"
     ]
    }
   ],
   "source": [
    "# get_len = lambda x : len(x)\n",
    "\n",
    "# train_df['input_length'] = train_df['input'].apply(get_len)\n",
    "# train_df['output_length'] = train_df['output'].apply(get_len)\n",
    "# val_df['input_length'] = val_df['input'].apply(get_len)\n",
    "# val_df['output_length'] = val_df['output'].apply(get_len)\n",
    "\n",
    "# print(max(train_df['input_length']), max(train_df['output_length']), max(val_df['input_length']), max(val_df['output_length']))\n",
    "# print(min(train_df['input_length']), min(train_df['output_length']), min(val_df['input_length']), min(val_df['output_length']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForCausalLM were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['roberta.encoder.layer.0.crossattention.self.query.weight', 'roberta.encoder.layer.0.crossattention.self.query.bias', 'roberta.encoder.layer.0.crossattention.self.key.weight', 'roberta.encoder.layer.0.crossattention.self.key.bias', 'roberta.encoder.layer.0.crossattention.self.value.weight', 'roberta.encoder.layer.0.crossattention.self.value.bias', 'roberta.encoder.layer.0.crossattention.output.dense.weight', 'roberta.encoder.layer.0.crossattention.output.dense.bias', 'roberta.encoder.layer.0.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.0.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.1.crossattention.self.query.weight', 'roberta.encoder.layer.1.crossattention.self.query.bias', 'roberta.encoder.layer.1.crossattention.self.key.weight', 'roberta.encoder.layer.1.crossattention.self.key.bias', 'roberta.encoder.layer.1.crossattention.self.value.weight', 'roberta.encoder.layer.1.crossattention.self.value.bias', 'roberta.encoder.layer.1.crossattention.output.dense.weight', 'roberta.encoder.layer.1.crossattention.output.dense.bias', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.2.crossattention.self.query.weight', 'roberta.encoder.layer.2.crossattention.self.query.bias', 'roberta.encoder.layer.2.crossattention.self.key.weight', 'roberta.encoder.layer.2.crossattention.self.key.bias', 'roberta.encoder.layer.2.crossattention.self.value.weight', 'roberta.encoder.layer.2.crossattention.self.value.bias', 'roberta.encoder.layer.2.crossattention.output.dense.weight', 'roberta.encoder.layer.2.crossattention.output.dense.bias', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.3.crossattention.self.query.weight', 'roberta.encoder.layer.3.crossattention.self.query.bias', 'roberta.encoder.layer.3.crossattention.self.key.weight', 'roberta.encoder.layer.3.crossattention.self.key.bias', 'roberta.encoder.layer.3.crossattention.self.value.weight', 'roberta.encoder.layer.3.crossattention.self.value.bias', 'roberta.encoder.layer.3.crossattention.output.dense.weight', 'roberta.encoder.layer.3.crossattention.output.dense.bias', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.4.crossattention.self.query.weight', 'roberta.encoder.layer.4.crossattention.self.query.bias', 'roberta.encoder.layer.4.crossattention.self.key.weight', 'roberta.encoder.layer.4.crossattention.self.key.bias', 'roberta.encoder.layer.4.crossattention.self.value.weight', 'roberta.encoder.layer.4.crossattention.self.value.bias', 'roberta.encoder.layer.4.crossattention.output.dense.weight', 'roberta.encoder.layer.4.crossattention.output.dense.bias', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.5.crossattention.self.query.weight', 'roberta.encoder.layer.5.crossattention.self.query.bias', 'roberta.encoder.layer.5.crossattention.self.key.weight', 'roberta.encoder.layer.5.crossattention.self.key.bias', 'roberta.encoder.layer.5.crossattention.self.value.weight', 'roberta.encoder.layer.5.crossattention.self.value.bias', 'roberta.encoder.layer.5.crossattention.output.dense.weight', 'roberta.encoder.layer.5.crossattention.output.dense.bias', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.6.crossattention.self.query.weight', 'roberta.encoder.layer.6.crossattention.self.query.bias', 'roberta.encoder.layer.6.crossattention.self.key.weight', 'roberta.encoder.layer.6.crossattention.self.key.bias', 'roberta.encoder.layer.6.crossattention.self.value.weight', 'roberta.encoder.layer.6.crossattention.self.value.bias', 'roberta.encoder.layer.6.crossattention.output.dense.weight', 'roberta.encoder.layer.6.crossattention.output.dense.bias', 'roberta.encoder.layer.6.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.6.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.7.crossattention.self.query.weight', 'roberta.encoder.layer.7.crossattention.self.query.bias', 'roberta.encoder.layer.7.crossattention.self.key.weight', 'roberta.encoder.layer.7.crossattention.self.key.bias', 'roberta.encoder.layer.7.crossattention.self.value.weight', 'roberta.encoder.layer.7.crossattention.self.value.bias', 'roberta.encoder.layer.7.crossattention.output.dense.weight', 'roberta.encoder.layer.7.crossattention.output.dense.bias', 'roberta.encoder.layer.7.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.7.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.8.crossattention.self.query.weight', 'roberta.encoder.layer.8.crossattention.self.query.bias', 'roberta.encoder.layer.8.crossattention.self.key.weight', 'roberta.encoder.layer.8.crossattention.self.key.bias', 'roberta.encoder.layer.8.crossattention.self.value.weight', 'roberta.encoder.layer.8.crossattention.self.value.bias', 'roberta.encoder.layer.8.crossattention.output.dense.weight', 'roberta.encoder.layer.8.crossattention.output.dense.bias', 'roberta.encoder.layer.8.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.8.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.9.crossattention.self.query.weight', 'roberta.encoder.layer.9.crossattention.self.query.bias', 'roberta.encoder.layer.9.crossattention.self.key.weight', 'roberta.encoder.layer.9.crossattention.self.key.bias', 'roberta.encoder.layer.9.crossattention.self.value.weight', 'roberta.encoder.layer.9.crossattention.self.value.bias', 'roberta.encoder.layer.9.crossattention.output.dense.weight', 'roberta.encoder.layer.9.crossattention.output.dense.bias', 'roberta.encoder.layer.9.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.9.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.10.crossattention.self.query.weight', 'roberta.encoder.layer.10.crossattention.self.query.bias', 'roberta.encoder.layer.10.crossattention.self.key.weight', 'roberta.encoder.layer.10.crossattention.self.key.bias', 'roberta.encoder.layer.10.crossattention.self.value.weight', 'roberta.encoder.layer.10.crossattention.self.value.bias', 'roberta.encoder.layer.10.crossattention.output.dense.weight', 'roberta.encoder.layer.10.crossattention.output.dense.bias', 'roberta.encoder.layer.10.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.10.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.11.crossattention.self.query.weight', 'roberta.encoder.layer.11.crossattention.self.query.bias', 'roberta.encoder.layer.11.crossattention.self.key.weight', 'roberta.encoder.layer.11.crossattention.self.key.bias', 'roberta.encoder.layer.11.crossattention.self.value.weight', 'roberta.encoder.layer.11.crossattention.self.value.bias', 'roberta.encoder.layer.11.crossattention.output.dense.weight', 'roberta.encoder.layer.11.crossattention.output.dense.bias', 'roberta.encoder.layer.11.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.11.crossattention.output.LayerNorm.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n",
      "INFO:filelock:Lock 46916225404432 acquired on /home/zonghaiyao/.cache/huggingface/datasets/dcd4134ec0ad23f318793c6f8b77745d97efebf4b194bcb3c1ce90f867bec0cc.07d7a1ea4a0063d16947f4a5b5a7ad98ca747e989e62fd0b2c5aa4b606f70aca.py.lock\n",
      "INFO:filelock:Lock 46916225404432 released on /home/zonghaiyao/.cache/huggingface/datasets/dcd4134ec0ad23f318793c6f8b77745d97efebf4b194bcb3c1ce90f867bec0cc.07d7a1ea4a0063d16947f4a5b5a7ad98ca747e989e62fd0b2c5aa4b606f70aca.py.lock\n",
      "INFO:filelock:Lock 46916157612176 acquired on /home/zonghaiyao/.cache/huggingface/datasets/c7db30bf448719bd2c2ee7c233832963ab2e0b85e984dda4f577016390fa0e85.7927df63b30f94ac549ad2d2e3c61c5089402aacb0ab0478007e0abfe3431378.py.lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 46916157612176 released on /home/zonghaiyao/.cache/huggingface/datasets/c7db30bf448719bd2c2ee7c233832963ab2e0b85e984dda4f577016390fa0e85.7927df63b30f94ac549ad2d2e3c61c5089402aacb0ab0478007e0abfe3431378.py.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a835ea391fd94d698163a0bce7e457b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "349367f4caa6479f93c6a83c93ea69ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=123.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f11a1928c24f4462b6b9a5300df11dee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=30.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f9150b63d2b4c40afe9c526a2da45fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=185.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/nfs/work1/llcao/zonghaiyao/tweetNorm/datasets/src/datasets/arrow_dataset.py:835: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return torch.tensor(x, **format_kwargs)\n",
      "ERROR:wandb.jupyter:Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
      "wandb: Currently logged in as: iesl-boxes (use `wandb login --relogin` to force relogin)\n",
      "wandb: Tracking run with wandb version 0.10.2\n",
      "wandb: Run data is saved locally in wandb/run-20200928_013639-2d78mctx\n",
      "wandb: Syncing run bertweet2bertweet_notebook\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/zonghaiyao/tweetnorm\" target=\"_blank\">https://wandb.ai/zonghaiyao/tweetnorm</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/zonghaiyao/tweetnorm/runs/2d78mctx\" target=\"_blank\">https://wandb.ai/zonghaiyao/tweetnorm/runs/2d78mctx</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'loss': 12.130699920654298, 'learning_rate': 2e-05, 'epoch': 0.10810810810810811, 'total_flos': 146877438197760, 'step': 20}\n",
      "{'loss': 8.481720733642579, 'learning_rate': 4e-05, 'epoch': 0.21621621621621623, 'total_flos': 293754876395520, 'step': 40}\n",
      "{'loss': 7.3166015625, 'learning_rate': 4.990909090909091e-05, 'epoch': 0.32432432432432434, 'total_flos': 440632314593280, 'step': 60}\n",
      "{'loss': 7.158120727539062, 'learning_rate': 4.9727272727272725e-05, 'epoch': 0.43243243243243246, 'total_flos': 587509752791040, 'step': 80}\n",
      "{'loss': 7.030865478515625, 'learning_rate': 4.9545454545454553e-05, 'epoch': 0.5405405405405406, 'total_flos': 734387190988800, 'step': 100}\n",
      "{'loss': 7.060699462890625, 'learning_rate': 4.936363636363637e-05, 'epoch': 0.6486486486486487, 'total_flos': 881264629186560, 'step': 120}\n",
      "{'loss': 7.253659057617187, 'learning_rate': 4.9181818181818183e-05, 'epoch': 0.7567567567567568, 'total_flos': 1028142067384320, 'step': 140}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-70eb5a94ce72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;31m# start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tweetNorm/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model_path, trial)\u001b[0m\n\u001b[1;32m    778\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m                 \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_flos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating_point_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tweetNorm/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1091\u001b[0m                 \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tweetNorm/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tweetNorm/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import nlp\n",
    "import logging\n",
    "from datasets import load_metric, Dataset\n",
    "from transformers import AutoTokenizer, EncoderDecoderModel, Trainer, TrainingArguments\n",
    "import pandas as pd\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "model = EncoderDecoderModel.from_encoder_decoder_pretrained(\"vinai/bertweet-base\", \"vinai/bertweet-base\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", normalization=True)\n",
    "\n",
    "# load train and validation data\n",
    "train_dataset = pd.read_json(\"WNUT2015_dataset/train_data.json\", orient=\"records\")\n",
    "val_dataset = pd.read_json(\"WNUT2015_dataset/test_truth.json\", orient=\"records\")\n",
    "\n",
    "make_sentence = lambda x : \" \".join(x)\n",
    "\n",
    "train_dataset['input_sentence'] = train_dataset['input'].apply(make_sentence)\n",
    "train_dataset['output_sentence'] = train_dataset['output'].apply(make_sentence)\n",
    "val_dataset['input_sentence'] = val_dataset['input'].apply(make_sentence)\n",
    "val_dataset['output_sentence'] = val_dataset['output'].apply(make_sentence)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_dataset)\n",
    "val_dataset = Dataset.from_pandas(val_dataset)\n",
    "\n",
    "# load rouge for validation\n",
    "#rouge = nlp.load_metric(\"rouge\")\n",
    "rouge = load_metric('rouge', experiment_id=8)\n",
    "bleu = load_metric('bleu', experiment_id=8)\n",
    "\n",
    "# set decoding params\n",
    "model.config.decoder_start_token_id = tokenizer.bos_token_id\n",
    "model.config.eos_token_id = tokenizer.eos_token_id\n",
    "model.config.max_length = 128\n",
    "model.config.min_length = 0\n",
    "model.config.no_repeat_ngram_size = 3\n",
    "model.early_stopping = True\n",
    "model.length_penalty = 2.0\n",
    "model.num_beams = 4\n",
    "\n",
    "\n",
    "# map data correctly\n",
    "def map_to_encoder_decoder_inputs(batch):\n",
    "    # Tokenizer will automatically set [BOS] <text> [EOS]\n",
    "    inputs = tokenizer(batch[\"input_sentence\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "    outputs = tokenizer(batch[\"output_sentence\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "    batch[\"input_ids\"] = inputs.input_ids    \n",
    "    batch[\"attention_mask\"] = inputs.attention_mask\n",
    "\n",
    "    batch[\"decoder_input_ids\"] = outputs.input_ids\n",
    "    batch[\"labels\"] = outputs.input_ids.copy()\n",
    "    # mask loss for padding\n",
    "    batch[\"labels\"] = [\n",
    "        [-100 if token == tokenizer.pad_token_id else token for token in labels] for labels in batch[\"labels\"]\n",
    "    ]\n",
    "    batch[\"decoder_attention_mask\"] = outputs.attention_mask\n",
    "\n",
    "    assert all([len(x) == 128 for x in inputs.input_ids])\n",
    "    assert all([len(x) == 128 for x in outputs.input_ids])\n",
    "    \n",
    "    return batch\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    # all unnecessary tokens are removed\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "    \n",
    "    metrics_rouge = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge1\", \"rouge2\", \"rouge3\", \"rouge4\", \"rougeL\", \"rougeLsum\"])\n",
    "\n",
    "    def batch_convert_ids_to_tokens(sequences, **kwargs):\n",
    "        return [tokenizer.convert_ids_to_tokens(seq, **kwargs) for seq in sequences]\n",
    "    \n",
    "    pred_tokens = batch_convert_ids_to_tokens(pred_ids, skip_special_tokens=True)\n",
    "    \n",
    "    def batch_convert_ids_to_tokens(sequences, **kwargs):\n",
    "        return [[tokenizer.convert_ids_to_tokens(seq, **kwargs)] for seq in sequences]\n",
    "    \n",
    "    label_tokens = batch_convert_ids_to_tokens(labels_ids, skip_special_tokens=True)\n",
    "    \n",
    "    metrics_bleu = bleu.compute(predictions=pred_tokens, references=label_tokens)\n",
    "    \n",
    "    return {\n",
    "        \"rouge1_precision\": round(metrics_rouge['rouge1'].mid.precision, 4),\n",
    "        \"rouge1_recall\": round(metrics_rouge['rouge1'].mid.recall, 4),\n",
    "        \"rouge1_fmeasure\": round(metrics_rouge['rouge1'].mid.fmeasure, 4),\n",
    "        \"rouge2_precision\": round(metrics_rouge['rouge2'].mid.precision, 4),\n",
    "        \"rouge2_recall\": round(metrics_rouge['rouge2'].mid.recall, 4),\n",
    "        \"rouge2_fmeasure\": round(metrics_rouge['rouge2'].mid.fmeasure, 4),\n",
    "        \"rouge3_precision\": round(metrics_rouge['rouge3'].mid.precision, 4),\n",
    "        \"rouge3_recall\": round(metrics_rouge['rouge3'].mid.recall, 4),\n",
    "        \"rouge3_fmeasure\": round(metrics_rouge['rouge3'].mid.fmeasure, 4),\n",
    "        \"rouge4_precision\": round(metrics_rouge['rouge4'].mid.precision, 4),\n",
    "        \"rouge4_recall\": round(metrics_rouge['rouge4'].mid.recall, 4),\n",
    "        \"rouge4_fmeasure\": round(metrics_rouge['rouge4'].mid.fmeasure, 4),\n",
    "        \"rougeL_precision\": round(metrics_rouge['rougeL'].mid.precision, 4),\n",
    "        \"rougeL_recall\": round(metrics_rouge['rougeL'].mid.recall, 4),\n",
    "        \"rougeL_fmeasure\": round(metrics_rouge['rougeL'].mid.fmeasure, 4),\n",
    "        \"rougeLsum_precision\": round(metrics_rouge['rougeLsum'].mid.precision, 4),\n",
    "        \"rougeLsum_recall\": round(metrics_rouge['rougeLsum'].mid.recall, 4),\n",
    "        \"rougeLsum_fmeasure\": round(metrics_rouge['rougeLsum'].mid.fmeasure, 4),\n",
    "        \"bleu\": round(metrics_bleu['bleu'], 4),\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# set batch size here\n",
    "batch_size = 16\n",
    "\n",
    "# make train dataset ready\n",
    "train_dataset = train_dataset.map(\n",
    "    map_to_encoder_decoder_inputs, batched=True, batch_size=batch_size, remove_columns=[\"input_sentence\", \"output_sentence\"],\n",
    ")\n",
    "train_dataset.set_format(\n",
    "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",
    ")\n",
    "\n",
    "# same for validation dataset\n",
    "val_dataset = val_dataset.map(\n",
    "    map_to_encoder_decoder_inputs, batched=True, batch_size=batch_size, remove_columns=[\"input_sentence\", \"output_sentence\"],\n",
    ")\n",
    "val_dataset.set_format(\n",
    "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",
    ")\n",
    "\n",
    "# set training arguments - these params are not really tuned, feel free to change\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./models/bertweet2bertweet/1/\",\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    predict_from_generate=True,\n",
    "    evaluate_during_training=True,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    logging_steps=20,\n",
    "    save_steps=500,\n",
    "    eval_steps=300,\n",
    "    overwrite_output_dir=True,\n",
    "    warmup_steps=50,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=30,\n",
    "    run_name=\"bertweet2bertweet_notebook\",\n",
    ")\n",
    "\n",
    "\n",
    "# instantiate trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")\n",
    "\n",
    "\n",
    "# start training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertLMHeadModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertLMHeadModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.value.weight', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'cls.predictions.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:filelock:Lock 46916595310224 acquired on /home/zonghaiyao/.cache/huggingface/datasets/dcd4134ec0ad23f318793c6f8b77745d97efebf4b194bcb3c1ce90f867bec0cc.07d7a1ea4a0063d16947f4a5b5a7ad98ca747e989e62fd0b2c5aa4b606f70aca.py.lock\n",
      "INFO:filelock:Lock 46916595310224 released on /home/zonghaiyao/.cache/huggingface/datasets/dcd4134ec0ad23f318793c6f8b77745d97efebf4b194bcb3c1ce90f867bec0cc.07d7a1ea4a0063d16947f4a5b5a7ad98ca747e989e62fd0b2c5aa4b606f70aca.py.lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 46916595468880 acquired on /home/zonghaiyao/.cache/huggingface/datasets/c7db30bf448719bd2c2ee7c233832963ab2e0b85e984dda4f577016390fa0e85.7927df63b30f94ac549ad2d2e3c61c5089402aacb0ab0478007e0abfe3431378.py.lock\n",
      "INFO:filelock:Lock 46916595468880 released on /home/zonghaiyao/.cache/huggingface/datasets/c7db30bf448719bd2c2ee7c233832963ab2e0b85e984dda4f577016390fa0e85.7927df63b30f94ac549ad2d2e3c61c5089402aacb0ab0478007e0abfe3431378.py.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ae089f5d86f4508b3e9868192392e1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f96340d2af624def92b040d01716ce19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17650b1d3c6449748e5a685945801052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=30.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "709bb235cd4a4905afd9f7ad11945729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=7.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/nfs/work1/llcao/zonghaiyao/tweetNorm/datasets/src/datasets/arrow_dataset.py:835: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return torch.tensor(x, **format_kwargs)\n",
      "/home/zonghaiyao/anaconda3/envs/tweetNorm/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff147dfc5cd42f39a7563ff59e75cb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=7.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed2a249591a440b0a222d72ea44d0ea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=7.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:wandb.jupyter:Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
      "wandb: Currently logged in as: iesl-boxes (use `wandb login --relogin` to force relogin)\n",
      "wandb: Tracking run with wandb version 0.10.2\n",
      "wandb: Run data is saved locally in wandb/run-20200926_141934-zar25jca\n",
      "wandb: Syncing run bert2bert\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/zonghaiyao/tweetnorm\" target=\"_blank\">https://wandb.ai/zonghaiyao/tweetnorm</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/zonghaiyao/tweetnorm/runs/zar25jca\" target=\"_blank\">https://wandb.ai/zonghaiyao/tweetnorm/runs/zar25jca</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'loss': 9.228541564941406, 'learning_rate': 2e-05, 'epoch': 2.857142857142857, 'total_flos': 56366881910784, 'step': 20}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7744d403ebb045618de0bbcc163266cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=7.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9247762c061b473c97a28f36ed6f1409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=7.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zonghaiyao/anaconda3/envs/tweetNorm/lib/python3.7/site-packages/transformers/trainer.py:1416: FutureWarning: The `_prediction_loop` method is deprecated and won't be called in a future version, define `prediction_loop` in your subclass.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b30f68b1db9f4a8097a2b37755204217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=1.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 102 (first `eos_token_id`) to generate sequence\n",
      "INFO:filelock:Lock 46915959187280 acquired on /home/zonghaiyao/.cache/huggingface/metrics/rouge/default/1-1-0.arrow.lock\n",
      "INFO:filelock:Lock 46915959187280 released on /home/zonghaiyao/.cache/huggingface/metrics/rouge/default/1-1-0.arrow.lock\n",
      "INFO:filelock:Lock 46915959182416 acquired on /home/zonghaiyao/.cache/huggingface/metrics/rouge/default/1-1-0.arrow.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:/mnt/nfs/work1/llcao/zonghaiyao/tweetNorm/datasets/src/datasets/metric.py:Removing /home/zonghaiyao/.cache/huggingface/metrics/rouge/default/1-1-0.arrow\n",
      "INFO:filelock:Lock 46915959182416 released on /home/zonghaiyao/.cache/huggingface/metrics/rouge/default/1-1-0.arrow.lock\n",
      "INFO:filelock:Lock 46916599933648 acquired on /home/zonghaiyao/.cache/huggingface/metrics/bleu/default/1-1-0.arrow.lock\n",
      "INFO:filelock:Lock 46916599933648 released on /home/zonghaiyao/.cache/huggingface/metrics/bleu/default/1-1-0.arrow.lock\n",
      "INFO:filelock:Lock 46915958811088 acquired on /home/zonghaiyao/.cache/huggingface/metrics/bleu/default/1-1-0.arrow.lock\n",
      "INFO:/mnt/nfs/work1/llcao/zonghaiyao/tweetNorm/datasets/src/datasets/metric.py:Removing /home/zonghaiyao/.cache/huggingface/metrics/bleu/default/1-1-0.arrow\n",
      "INFO:filelock:Lock 46915958811088 released on /home/zonghaiyao/.cache/huggingface/metrics/bleu/default/1-1-0.arrow.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 7.500368595123291, 'eval_rouge1_precision': 0.0733, 'eval_rouge1_recall': 0.0077, 'eval_rouge1_fmeasure': 0.0139, 'eval_rouge2_precision': 0.0, 'eval_rouge2_recall': 0.0, 'eval_rouge2_fmeasure': 0.0, 'eval_rouge3_precision': 0.0, 'eval_rouge3_recall': 0.0, 'eval_rouge3_fmeasure': 0.0, 'eval_rouge4_precision': 0.0, 'eval_rouge4_recall': 0.0, 'eval_rouge4_fmeasure': 0.0, 'eval_rougeL_precision': 0.0733, 'eval_rougeL_recall': 0.0077, 'eval_rougeL_fmeasure': 0.0139, 'eval_rougeLsum_precision': 0.0733, 'eval_rougeLsum_recall': 0.0077, 'eval_rougeLsum_fmeasure': 0.0139, 'eval_bleu': 0.0, 'epoch': 4.285714285714286, 'total_flos': 82265179004928, 'step': 30}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f787217404f344fc9e8f15d9bc45572d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=7.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 7.050238037109375, 'learning_rate': 4e-05, 'epoch': 5.714285714285714, 'total_flos': 110448619960320, 'step': 40}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "961c7edecb98424c8eadac3cd57b4ecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=7.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0852546cbbea433fa0cad93a1c4dc71b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=7.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nlp\n",
    "import logging\n",
    "from datasets import load_metric\n",
    "from transformers import BertTokenizer, EncoderDecoderModel, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "model = EncoderDecoderModel.from_encoder_decoder_pretrained(\"bert-base-uncased\", \"bert-base-uncased\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# CLS token will work as BOS token\n",
    "tokenizer.bos_token = tokenizer.cls_token\n",
    "\n",
    "# SEP token will work as EOS token\n",
    "tokenizer.eos_token = tokenizer.sep_token\n",
    "\n",
    "# load train and validation data\n",
    "train_dataset = pd.read_json(\"WNUT2015_dataset/train_data.json\", orient=\"records\")\n",
    "val_dataset = pd.read_json(\"WNUT2015_dataset/test_truth.json\", orient=\"records\")\n",
    "\n",
    "train_dataset = train_dataset[:100]\n",
    "val_dataset = val_dataset[:5]\n",
    "\n",
    "make_sentence = lambda x : \" \".join(x)\n",
    "\n",
    "train_dataset['input_sentence'] = train_dataset['input'].apply(make_sentence)\n",
    "train_dataset['output_sentence'] = train_dataset['output'].apply(make_sentence)\n",
    "val_dataset['input_sentence'] = val_dataset['input'].apply(make_sentence)\n",
    "val_dataset['output_sentence'] = val_dataset['output'].apply(make_sentence)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_dataset)\n",
    "val_dataset = Dataset.from_pandas(val_dataset)\n",
    "\n",
    "# load rouge for validation\n",
    "rouge = load_metric('rouge', experiment_id=1)\n",
    "bleu = load_metric('bleu', experiment_id=1)\n",
    "\n",
    "# set decoding params\n",
    "model.config.decoder_start_token_id = tokenizer.bos_token_id\n",
    "model.config.eos_token_id = tokenizer.eos_token_id\n",
    "model.config.max_length = 64\n",
    "model.config.min_length = 0\n",
    "model.config.no_repeat_ngram_size = 3\n",
    "model.early_stopping = True\n",
    "model.length_penalty = 2.0\n",
    "model.num_beams = 4\n",
    "\n",
    "\n",
    "# map data correctly\n",
    "def map_to_encoder_decoder_inputs(batch):\n",
    "    # Tokenizer will automatically set [BOS] <text> [EOS]\n",
    "    # cut off at BERT max length 512\n",
    "    inputs = tokenizer(batch[\"input_sentence\"], padding=\"max_length\", truncation=True, max_length=64)\n",
    "    # inputs = tokenizer(batch[\"input_sentence\"], padding=\"max_length\")\n",
    "    # force summarization <= 128\n",
    "    outputs = tokenizer(batch[\"output_sentence\"], padding=\"max_length\", truncation=True, max_length=64)\n",
    "    # outputs = tokenizer(batch[\"output_sentence\"], padding=\"max_length\")\n",
    "\n",
    "    batch[\"input_ids\"] = inputs.input_ids\n",
    "    batch[\"attention_mask\"] = inputs.attention_mask\n",
    "\n",
    "    batch[\"decoder_input_ids\"] = outputs.input_ids\n",
    "    batch[\"labels\"] = outputs.input_ids.copy()\n",
    "    # mask loss for padding\n",
    "    batch[\"labels\"] = [\n",
    "        [-100 if token == tokenizer.pad_token_id else token for token in labels] for labels in batch[\"labels\"]\n",
    "    ]\n",
    "    batch[\"decoder_attention_mask\"] = outputs.attention_mask\n",
    "\n",
    "    assert all([len(x) == 64 for x in inputs.input_ids])\n",
    "    assert all([len(x) == 64 for x in outputs.input_ids])\n",
    "    \n",
    "    return batch\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    # all unnecessary tokens are removed\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "    \n",
    "    metrics_rouge = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge1\", \"rouge2\", \"rouge3\", \"rouge4\", \"rougeL\", \"rougeLsum\"])\n",
    "    \n",
    "    def batch_convert_ids_to_tokens(sequences, **kwargs):\n",
    "        return [tokenizer.convert_ids_to_tokens(seq, **kwargs) for seq in sequences]\n",
    "    \n",
    "    pred_tokens = batch_convert_ids_to_tokens(pred_ids, skip_special_tokens=True)\n",
    "    \n",
    "    def batch_convert_ids_to_tokens(sequences, **kwargs):\n",
    "        return [[tokenizer.convert_ids_to_tokens(seq, **kwargs)] for seq in sequences]\n",
    "    \n",
    "    label_tokens = batch_convert_ids_to_tokens(labels_ids, skip_special_tokens=True)\n",
    "    \n",
    "    metrics_bleu = bleu.compute(predictions=pred_tokens, references=label_tokens)\n",
    "    \n",
    "    return {\n",
    "        \"rouge1_precision\": round(metrics_rouge['rouge1'].mid.precision, 4),\n",
    "        \"rouge1_recall\": round(metrics_rouge['rouge1'].mid.recall, 4),\n",
    "        \"rouge1_fmeasure\": round(metrics_rouge['rouge1'].mid.fmeasure, 4),\n",
    "        \"rouge2_precision\": round(metrics_rouge['rouge2'].mid.precision, 4),\n",
    "        \"rouge2_recall\": round(metrics_rouge['rouge2'].mid.recall, 4),\n",
    "        \"rouge2_fmeasure\": round(metrics_rouge['rouge2'].mid.fmeasure, 4),\n",
    "        \"rouge3_precision\": round(metrics_rouge['rouge3'].mid.precision, 4),\n",
    "        \"rouge3_recall\": round(metrics_rouge['rouge3'].mid.recall, 4),\n",
    "        \"rouge3_fmeasure\": round(metrics_rouge['rouge3'].mid.fmeasure, 4),\n",
    "        \"rouge4_precision\": round(metrics_rouge['rouge4'].mid.precision, 4),\n",
    "        \"rouge4_recall\": round(metrics_rouge['rouge4'].mid.recall, 4),\n",
    "        \"rouge4_fmeasure\": round(metrics_rouge['rouge4'].mid.fmeasure, 4),\n",
    "        \"rougeL_precision\": round(metrics_rouge['rougeL'].mid.precision, 4),\n",
    "        \"rougeL_recall\": round(metrics_rouge['rougeL'].mid.recall, 4),\n",
    "        \"rougeL_fmeasure\": round(metrics_rouge['rougeL'].mid.fmeasure, 4),\n",
    "        \"rougeLsum_precision\": round(metrics_rouge['rougeLsum'].mid.precision, 4),\n",
    "        \"rougeLsum_recall\": round(metrics_rouge['rougeLsum'].mid.recall, 4),\n",
    "        \"rougeLsum_fmeasure\": round(metrics_rouge['rougeLsum'].mid.fmeasure, 4),\n",
    "        \"bleu\": round(metrics_bleu['bleu'], 4),\n",
    "    }\n",
    "\n",
    "\n",
    "# set batch size here\n",
    "batch_size = 16\n",
    "\n",
    "# make train dataset ready\n",
    "train_dataset = train_dataset.map(\n",
    "    map_to_encoder_decoder_inputs, batched=True, batch_size=batch_size, remove_columns=[\"input_sentence\", \"output_sentence\"],\n",
    ")\n",
    "train_dataset.set_format(\n",
    "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",
    ")\n",
    "\n",
    "# same for validation dataset\n",
    "val_dataset = val_dataset.map(\n",
    "    map_to_encoder_decoder_inputs, batched=True, batch_size=batch_size, remove_columns=[\"input_sentence\", \"output_sentence\"],\n",
    ")\n",
    "val_dataset.set_format(\n",
    "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",
    ")\n",
    "\n",
    "# set training arguments - these params are not really tuned, feel free to change\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./models/bert2bert/1/\",\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    predict_from_generate=True,\n",
    "    evaluate_during_training=True,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    logging_steps=20,\n",
    "    save_steps=500,\n",
    "    eval_steps=30,\n",
    "    overwrite_output_dir=True,\n",
    "    warmup_steps=50,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=30,\n",
    "    fp16=True,\n",
    "    run_name=\"bert2bert\",\n",
    ")\n",
    "\n",
    "# instantiate trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")\n",
    "\n",
    "\n",
    "# start training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"labels\"] = \n",
    "[[-100 if mask == 0 else token for mask, token in mask_and_tokens] for mask_and_tokens in [zip(masks, labels) for masks, labels in zip(batch[\"decoder_attention_mask\"], batch[\"labels\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
